# 드론 LED 킻 카메라와 가시광 통신을 위한 드론 포지셔닝
## Abstract
세상은 종종 재난에 시달립니다. 
주문형 드론 장착 가시 광선 통신 (VLC) 네트워크는 재해 대응 작업을 활용하기 위해 재해 피해 지역을 모니터링하는 데 적합합니다. 
이미지 센서 기반의 VLC 개념도 최근 불안정하게 움직이는 드론을 이용한 안정적인 링크 구축으로 주목을 받고있다. 
그러나 기존 작업에서는 일대 다 이미지 센서 기반 VLC 시스템을 충분히 고려하지 않았습니다. 
따라서 본 논문에서는 VLC 링크 간의 간섭을 피하기 위해 드론 포지셔닝 알고리즘을 사용하여 카메라와 여러 드론에 장착 된 LED 조명 간의 일대 다 이미지 센서 기반 VLC 개념을 제안합니다. 
여러 드론이 재난 피해 지역에 주문형으로 배치되어 지상을 모니터링하고 이미지 센서 기반 가시 광선 통신 (VLC) 링크를 통해 이미지 데이터를 카메라에 지속적으로 전송합니다. 
제안 된 아이디어는 LED 패널과 4K 카메라가 장착 된 드론으로 구현 된 PoC (개념 증명)로 입증됩니다. 
그 결과 제안 된 시스템의 타당성을 확인했습니다.

## 1. INTRODUCTION
세계는 종종 지진, 허리케인, 쓰나미를 포함한 재앙적인 재난에 시달리고 있습니다 [1], [2].
광섬유 케이블과 같은 시설의 파괴 또는 에너지 공급 중단으로 인해 재난 피해 지역에서 통신 서비스를 사용할 수 없게됩니다.
재난 대응 및 인명 구조 운영을 위해 이러한 영역에서 통신 네트워크를 신속하게 복구하는 것이 중요한 문제였습니다. 
무선 바이 패스 경로를 설정하여 생존 시설을 사용하는 복구 방안이 제안되었지만 [3] – [5] 대규모 정전이 발생하면 그러한 접근 방식을 채택하기가 어렵습니다.
재난 후 모니터링을위한 유망한 솔루션은 많은 드론이 재난 피해 지역에 주문형으로 유연하게 배치 될 수 있기 때문에 드론 장착 무선 네트워크를 사용하는 것입니다.
주문형 드론 탑재 네트워크는 부상자 찾기와 같은 재난 대응 작업을 활용하기 위해 대상 지역의 현재 상황을 파악하는 데 적합합니다  
  
드론으로 강화 된 무선 네트워크의 개념은 공공 안전 네트워크를 배치하기위한 뜨거운 연구 주제였습니다 [6], [7]. 
재난 후 상황에 대해 비행 셀룰러 네트워크의 확률 적 기하학 기반 설계가 [8]에서 제안되었습니다. 
비행 네트워크의 효과는이 작업에서 입증되었습니다. 
드론의 수와 해당 고도를 최적으로 선택하여 지상 커버리지를 향상시킬 수 있습니다. 
또한, 기존의 포화 된 지상 인프라를 강화하기 위해 드론이 장착 된 LTE 펨토셀 기지국이 [9]에서 조사되었습니다. 
그들은 도시의 모든 사용자를 다루기 위해 많은 수의 드론이 필요하지만 비행 기지국의 유효성을 보여주는 초기 결과를 제시했습니다. 
드론에 대한 VLC의 개념은 유연한 통신과 조명을 동시에 제공하기 위해 [10]에서 연구되었습니다. 
노드 및 셀 연결의 위치는 조명 및 통신 제약 조건에서 전력 소비를 최소화하도록 최적화되었습니다.
그러나 기존의 드론 탑재 무선 네트워크는 재난 후 모니터링을 위해 많은 드론에 의한 애드혹 네트워크 구축에 집중하지 않았습니다.  
  
이 문제를 해결하기 위해 본 논문에서는 다수의 드론과 이미지 센서를 이용한 가시광 애드혹 네트워크의 개념과 예비 결과를 제안한다. 
제안 된 접근 방식의이면에있는 아이디어는 정전 지역에서 조명과 통신 모두에 온보드 LED 조명을 활용하는 것입니다. 
여러 대의 드론이 재난 피해 지역에 주문형으로 배치되어 지상을 모니터링하고 이미지 센서 기반 가시광 통신 (VLC) 링크를 통해 이미지 데이터를 카메라에 지속적으로 전송합니다.
이 논문은 또한 VLC 링크 간의 간섭을 피하기 위해 여러 드론에 대한 위치 결정 알고리즘을 제안합니다.
이는 카메라가 여러 개의 드론에 장착 된 LED로부터 광학 신호를 수신하기 때문에 드론이 촬영 요건을 충족하는 중첩을 피하기 위해 이동해야하기 때문입니다. 즉, 인식 가능한 드론의 범위는 카메라의 초점 거리를 포함한 조건에 따라 결정됩니다.
제안 된 아이디어는 LED 패널과 4K 카메라가 장착 된 드론으로 구현 된 PoC (개념 증명)로 입증됩니다.  
  
이 문서의 나머지 부분은 다음과 같이 구성됩니다. 
섹션 II에서는 VLC 관련 작업과이 작업의 기여를 소개합니다. 
섹션 III는 제안 된 계획을 설명합니다. 섹션 IV는 제안 된 위치 결정 알고리즘과 시뮬레이션 결과를 제시합니다. 
섹션 V는 구현 된 PoC를 사용한 실험 결과를 설명합니다. 
마지막으로, 결론은 섹션 VI에서 제공됩니다.  
  
## 2. RELATED WORK
드론을 이용한 자유 공간 광학 (FSO) 통신은 최근에 집중적으로 연구되었습니다. 
신속한 이벤트 대응과 유연한 배치를 위해 드론을 사용하는 에지 컴퓨팅 기반 무선 액세스 네트워크 아키텍처가 [11]에서 제안되었습니다.
여기서 드론과 지상 노드 간의 FSO 통신을 통해 프론트 홀 및 백홀 링크가 설정되었습니다. 
ad hoc mesh FSO 네트워크에서 난류 유도 신호 페이드는 대기 채널의 감쇠 및 위상 왜곡의 영향에 대한 지식을 얻기 위해 실험적으로 [12]에서 측정되었습니다.
FSO 기반 드론 지원 모바일 액세스 네트워크는 재난 대응 목적으로 [13]에서 조사되었습니다. 
드론과 모바일 사용자 협회의 배치는 재난 피해 지역에서 서비스를받는 사용자 수를 최대화하기 위해 공동으로 최적화되었습니다. 
그러나 FSO 기반 통신에서 가장 큰 어려움은 송수신기와 수신기 사이에 광축을 구성하는 것입니다. 
광축이 일치하지 않으면 수신 된 광 출력이 크게 감소합니다. 
이러한 특성으로 인해 FSO는 고정 접지 노드 간의 통신에 적합합니다. 
대부분의 드론은 바람에 의해 공중에서 불안정하게 움직이기 때문에 광축을 동적으로 조정하기가 어렵습니다.  
  
이 문제를 해결하기 위해 광 신호를 수신하는 카메라 시스템 개념이 많은 관심을 끌었다. 
[14]에서는 차량에 LED 송신기와 비디오 카메라가 장착 된 VLC 기반 V2V (vehicle-to-vehicle) 통신 시스템이 개발되었습니다. 
드론에 장착 된 LED 조명과 카메라 사이의 VLC와 관련하여 드론과 지상 기지국을 사용한 PoC 테스트 결과가 [15]에보고되었습니다. 
그러나이 작업의 주요 한계는  

1) 드론 한 대와 카메라 한 대의 신호 품질을 측정하는 것, 
2) 이미지에서 드론의 위치를 ​​인식하지 못하는 것입니다.   

따라서 본 논문의 공헌은 VLC 링크 간 간섭을 피하기 위해 드론 포지셔닝 알고리즘을 사용하여 카메라와 여러 드론 장착형 LED 조명 간의 일대 다 이미지 센서 기반 VLC 개념을 제안하는 것입니다. 
또한 제안 된 방안에 대한 예비 결과를 제시한다.  
  
  
## 2. PROPOSED SCHEME
### A. Concept
드론이 장착 된 LED 조명과 카메라 사이의 VLC 개념적 시스템 아키텍처는 그림 1에 나와 있습니다.
재해 후 모니터링을위한 애드혹 네트워크를 구성하기 위해 여러 드론이 재난 피해 지역에 배치됩니다.
각 드론은 온보드 카메라로 지상을 촬영합니다. 
드론은 온보드 LED 조명을 사용하여 녹화 된 이미지를 VLC가있는 지상 카메라로 전송합니다.
카메라는 드론과 그 위에 장착 된 LED 조명을 촬영하고 데이터를 에지 서버로 전송합니다.
에지 서버는 수신 된 이미지에서 드론을 감지하고 LED 조명의 신호를 복조합니다.
에지 서버는 드론 감지 후에 만 ​​LED 조명의 신호를 복조 할 수 있습니다.  
  
![그림 1](./img/fig1.PNG)
###### [그림 1] Concept of VLC between drone-mounted LED and camera  
  
제안 된 드론 포지셔닝 알고리즘의 목표는 VLC 링크를 통해 효율적인 데이터 전송을 달성하는 것입니다. 
드론의 궤적은 겹침을 피하기 위해 결정되며 촬영 요건을 충족하고 외부 조건을 고려하여 인식 가능한 드론의 범위를 보장합니다. 
VLC를위한 드론 측위 모델은 다음과 같이 정의되며, 모델을 기반으로 측위 알고리즘을 제안한다. 
제안 된 계획은 복구 작업을 활용하기 위해 재해 피해 지역의 실시간 모니터링을 가능하게합니다. 
가시 광선 사용은 대상 지역의 넓은 범위와 다목적 사용으로 인해 재해 후 모니터링에 적합합니다.  
  
### B. Image processing sequence
이 섹션에서는 에지 서버에서 이미지 처리 순서를 소개합니다. 
그림 2는 카메라로 촬영 한 이미지의 예를 보여줍니다. 
에지 서버는 먼저 DNN으로 드론을 감지합니다. 
여러 개의 드론이 이미지에 캡처되었으므로 이미지를 잘라 원본 파일에서 각 드론을 추출합니다.
잘린 이미지마다 드론에 장착 된 LED 조명의 신호가 감지되고 복조됩니다. 
복조 프로세스는 드론 감지가 성공한 경우에만 실행할 수 있으며, 그렇지 않으면 에지 서버가 온보드 LED를 가로등과 같은 다른 광원과 구별 할 수 없습니다. 
너무 멀리있는 드론은 너무 작아 인식 할 수 없습니다.  
  
![그림 2](./img/fig2.PNG)
###### [그림 2] Image filmed by camera  
  
### C. Model
1) 변수 정의 : 제안 된 모델에서 사용 된 변수는 표 1에 요약되어있다. 
각 변수에 대한 세부 사항은 다음과 같다. 
제안 된 모델에서 우리는 드론이 일반성을 잃지 않고 구체로 근사한다고 가정했습니다.  
  
![표 1](./img/table1.PNG)  
  
2) 드론 좌표 : 드론 세트를 표시하고 i와 j는 해당 드론의 식별자를 나타냅니다. 
각 드론이 GPS (Global Positioning System) 센서와 같은 센서를 사용하여 현재 위치를 측정한다고 가정합니다. 
원점은 위치를 나타내고 y 축은 각각 카메라의 방향을 나타냅니다. 
거리 r<sub>i</sub>는 (x<sub>i</sub>, y<sub>i</sub>, z<sub>i</sub>)에서 계산됩니다.  
  
3) 감지 범위 : 카메라의 광학 줌 배율을 M으로 정의하겠습니다. 
d<sub>w</sub>와 d<sub>h</sub>는 I에있는 모든 드론의 크기가 같다고 가정하고 드론의 ​​너비와 높이를 나타냅니다. 
M을 사용하면 다음과 같은 식을 얻을 수 있습니다.  
  
![방정식 1](./img/equation1.PNG)  
  
여기서 e<sub>h</sub>와 e<sub>h</sub>는 각각 카메라에서 촬영 된 드론의 너비와 높이를 나타냅니다.  
  
여기에 렌즈에 대한 일반적인 방정식이 있습니다.  
  
![방정식 2](./img/equation2.PNG)  
  
여기서 r은 드론과 렌즈 사이의 거리, b는 이미징 포인트와 렌즈 사이의 거리, f는 카메라의 초점 거리입니다.
그림 3은 그들 사이의 관계를 보여줍니다. 
M = b/r을 사용하면 (2)는 다음과 같이 변환됩니다.  
  
![그림 3](./img/fig3.PNG)
###### [그림 3] Size of imaged drone  
  
![방정식 3](./img/equation3.PNG)  
  
M과 f의 범위는 카메라 사양에 따라 결정됩니다. 
(3)에서 드론과 이미징 포인트 사이의 거리는 다음과 같이 공식화됩니다.  
  
![방정식 4](./img/equation4.PNG)  
  
![방정식 5](./img/equation5.PNG)  
  
![방정식 6](./img/equation6.PNG)  
  
따라서 초점 거리의 범위는 매개 변수 M 및 f에 의해 결정됩니다. 거리 L에서 일정 범위 내에있는 드론도 인식 할 수 있습니다. 
이 감지 범위는 2l로 정의됩니다. 
즉, (L - b) - l) ≤ r ≤ (L - b) + l 에 위치한 드론을 탐지 할 수 있습니다.  
  
4) 드론의 겹침 : 겹치는 드론은 별도로 인식 할 수 없기 때문에 촬영 된 이미지에서 드론의 겹침을 모델링합니다. 
다음 모델은 y 축이 카메라의 방향을 나타내므로 x-z 평면에서 설명됩니다. 
드론의 겹침을 피하기 위해 출입 금지 구역을 정의합니다. 
그림 4는 j 번째 드론에 의해 생성 된 i 번째 드론의 noentry 영역을 나타냅니다. 
i 번째 드론의 x-z 평면에 투영되는 j 번째 드론의 좌표는 다음과 같이 공식화됩니다.  
  
![그림 4](./img/fig4.PNG)  
###### No-entry area of drone  
  
![방정식 7](./img/equation7.PNG)  
  
투영 된 j 번째 드론의 반경은 다음과 같이 계산됩니다.  
  
![방정식 8](./img/equation8.PNG)  
  
i 번째 드론의 x-z 평면에서 i 번째 드론과 j 번째 드론 사이의 거리는 다음과 같이 계산됩니다.  
  
![방정식 9](./img/equation9.PNG)  
  
따라서 촬영 된 영상에서 i 번째 드론과 j 번째 드론이 겹치지 않는다는 제약은 다음과 같다.  
  
![방정식 10](./img/equation10.PNG)  
  
5) 드론 포지셔닝 제약 : 위 모델을 바탕으로 드론 포지셔닝 제약을 요약하면 다음과 같다.  
  
a) 감지 가능 범위 : I의 모든 드론이 감지 가능 범위 내에 있습니다.  
  
![방정식 11](./img/equation11.PNG)

b) 겹침 없음 : I의 모든 드론이 이미지에서 서로 겹치지 않습니다.  
  
![방정식 12](./img/equation12.PNG)  
  
## 4. DRONE POSITIONING ALGORITHM
이 섹션에서는 제안 된 드론 포지셔닝 알고리즘과 컴퓨터 시뮬레이션을 통한 평가 결과를 설명합니다.  
  
### A. Assumption
이 논문은 드론의 움직임에 대해 다음과 같은 가정을한다.  
  
<pre>
    * 각 드론의 목적지가 제공됩니다. 각 드론은 모니터링 목적으로 자체 목적지로 이동합니다.
    * 이동 거리는 에너지 소비를 고려하여 짧은 편이 선호됩니다.
    * 각 드론에는 목적지 좌표와 자신과 다른 드론의 현재 좌표에 대한 정보가 있습니다.
</pre>
  
### B. Algorithm
제안 된 알고리즘의 목표는 III-C5 절에 규정 된 제약 조건을 만족하는 드론의 이동 거리를 줄이는 것입니다. 
제안 된 알고리즘의 흐름도는 Fig. 5와 같다. 드론의 목적지 좌표가 주어진다.
각 드론은 GNSS를 사용하여 현재 좌표를 얻고 무선 통신을 통해 다른 사람에게보고합니다. 
그런 다음, 진입 금지 영역은 현재 좌표를 기반으로 섹션 III-C5에 설명 된 제약 조건으로 업데이트됩니다. 
기본적으로 드론은 목적지까지 최단 경로로 이동합니다. 
드론이 진입 금지 구역에 진입하면 겹치는 상대를 식별합니다. 
y<sub>own</sub>과 y<sub>other</sub>는 각각이 드론과 상대의 y 좌표를 나타냅니다. 
y<sub>own</sub> < y<sub>other</sub>가 만족되면 무인 항공기는 우회 경로의 길이를 줄이기 위해 진입 금지 영역을 피하기 위해 이동합니다.
그렇지 않으면 드론은 상대방이 진입 금지 구역을 피할 때까지 기다립니다.
그 후 최단 경로의 진입 금지 영역이 제거되면 이동을 다시 시작합니다.
드론이 일정 시간 이상 기다려야한다면 진입 금지 구역을 피해 이동하기 시작합니다.
결과적으로 모든 드론은 촬영 된 이미지에서 겹치지 않고 목적지에 도착할 수 있습니다.  
  
![그림 5](./img/fig5.PNG)  
###### [그림 5] Flowchart of the proposed algorithm  
  
### C. Simulation results
제안 된 알고리즘의 성능은 Python3로 작성된 자체 개발 시뮬레이터로 확인되었습니다. 
d<sub>r</sub> = 0 : 12m 인 드론 8 대를 6m 정사각형 영역에 배치합니다. 
그들은 모두 무작위로 결정된 시작 위치에서 목적지까지 1m / s의 속도로 이동했습니다. 
비행 높이는 3m에서 7m까지 다양했습니다. 
시뮬레이션은 10 회 반복되었습니다.  
  
Fig. 6은 드론의 이동 거리 증가 분포를 보여준다. 
진입 금지 구역을 피하기 위해 이동 한 드론 만 계산되었습니다. 
증가 된 거리는 약 50 %에서 1 미터 미만이었습니다.  
  
![그림 6](./img/fig6.PNG)  
###### [그림 6] Increase in moving distance 
  
그림 7은 드론의 대기 시간을 요약 한 것입니다. 
대부분의 경우 대기 시간의 증가는 1 초 이내였습니다.
이를 통해 제안 된 알고리즘과 중복되지 않도록 드론이 효율적으로 이동 함을 확인 하였다.  
  
![그림 7](./img/fig7.PNG)
###### [그림 7] Wait time  
  
또한 움직임을 피하는 예를 보여줍니다. 제안 된 알고리즘은 Unity 2019.4.12로 구현되었습니다. 
그림 8은 각 구가 드론을 나타내는 두 드론의 예를 보여줍니다.
드론은 가까이 다가 가기 위해 똑바로 움직였습니다. 
그런 다음 드론이 출입 금지 구역을 피하고 다른 드론은 기다렸다. 
드디어 정지 한 드론이 다시 움직이기 시작했습니다. 
그 결과, 촬영 된 이미지의 겹침이 성공적으로 방지되었습니다.  
  
![그림 8](./img/fig8.PNG)
###### [그림 8] Example case of two drones  
  
## 5. EXPERIMENTAL RESULTS
이 섹션에서는 드론 인식의 실험 결과를 제공합니다. 
우리는 다양한 환경에서 드론이 장착 된 LED 조명의 8000 개 데이터 세트를 얻었습니다. 
그런 다음 CNN (convolutional neural network)으로 인식 정확도를 평가했습니다.  
  
### A. Experimental condition
여기서 우리는 실험 조건을 설명합니다.
우리는 DaJiang Innovations Science and Technology (DJI) Co., Ltd에서 출시 한 두 대의 Mavic 2 Pro 드론을 사용했습니다. 
드론의 크기는 대략 d<sub>r</sub> = 12cm였습니다. 
LED 조명의 경우 WS2812B 직렬 LED 패널을 사용하여 정사각형에 16 개의 LED 조명을 배치했으며, 이는 World semi Co., Limited에서 생산했으며 9 개의 직렬 LED 패널이 각 드론에 송신기로 장착되었습니다. 
Arduino UNO 마이크로 컨트롤러를 직렬 LED 패널에 연결하여 제어했습니다. 
실험 장치는 그림 9에 나와 있습니다. 직렬 LED의 밝기는 충분한 전송 거리를 보장하기 위해 최대 값으로 설정되었습니다. 
수신기 측에는 Sony Xperia XZ 2 Premium 카메라가 사용되었습니다. 
해상도는 1080 1920, 픽셀 수는 2 메가 픽셀, 프레임 속도는 60fps였습니다. 
카메라 높이는 1 : 0m로 설정되었습니다. 
초점 거리는 f = 25mm이고 줌 배율은 M = 1로 설정되었습니다.  
  
![그림 9](./img/fig8.PNG)
###### [그림 9] Experimental device  
  
드론에 장착 된 송신기는 연속적인 빛을 보내 카메라로 촬영했습니다.
녹화 된 비디오는 일련의 정적 사진으로 분할되도록 에지 서버로 전송되었습니다.
우리는 CNN을 사용하는 유명한 기계 학습 모델 인 YOLOv3를 사용하여 에지 서버에서 수신 된 사진에서 송신기를 인식했습니다.  
  
드론에 장착 된 LED 조명의 감지 정확도를 보장하기 위해 훈련 데이터로 8000 장의 사진을 수집하고 드론의 ​​위치를 ​​표시했습니다.
이 과정에서 사진의 해상도는 360640으로 조정되었습니다. 
또한 다양한 조건에서 인식 정확도를 높이기 위해 카메라와 드론 사이의 거리를 변경하여 데이터 세트를 얻었습니다. 
이는 거리가 멀어짐에 따라 드론을 대표하는 픽셀 수가 감소하기 때문이다.  
  
### B. Results
인식 정확도에 대한 결과는 표 II에 요약되어 있습니다.
각 값은 각 거리에 대해 100 개의 테스트 이미지로 계산 된 인식률의 평균입니다. 
이 결과를 통해 드론이 장착 된 LED 조명은 카메라와 드론의 거리에 관계없이 정확하고 안정적으로 인식 할 수 있음을 확인했습니다. 
또한 송신기에서 데이터 신호를 복조 할 수있는 가능성을 확인했습니다.  
  
![표 2](./img/table2.PNG)
  
제안 된 포지셔닝 알고리즘의 유효성은 두 대의 드론으로 확인되었습니다.
그림 10은 드론 두 대의 인식 결과 예시를 사진으로 나타낸 것이다. 
이 예에서 카메라와 각 드론 사이의 거리는 모두 20m였습니다. 
섹션 III-C5에서 공식화 된 제약으로부터, 겹침을 피하기 위해 진입 금지 영역이 계산되었습니다. 
이러한 제약이 그림 10에서 만족 되었기 때문에 두 대의 드론이 별도로 인식되었다. 
따라서이 결과를 통해 제안 된 모델과 알고리즘의 타당성을 확인 하였다.  
  
![그림 10](./img/fig10.PNG)
###### [그림 10] Example recognition result of multiple drones  
  
### C. Discussion
실험에서 LED 조명의 색상은 그림 9와 같이 빨간색으로 설정되었습니다.
이 결정은 배경의 나무와 하늘을 고려한 결과입니다. 
식별하기 쉬운 색상은 외부 환경에 따라 달라 지므로 견고한 색상 설정을 조사해야합니다.
또한 더 많은 드론을 사용하는 실험이 더 연구되고 있습니다.  
  
## 6. CONCLUSION
이 논문은 카메라와 드론에 장착 된 여러 LED 조명 사이의 일대 다 이미지 센서 기반 VLC 개념을 제안했습니다. 
제안 된 아이디어는 불안정하게 움직이는 드론을 사용하는 일대 다 VLC 시스템을 가능하게합니다. 
제안 된 계획에 따라 여러 무인 항공기가 재난 피해 지역에 주문형으로 배치되어 지상을 모니터링하고 VLC 링크를 통해 지상 카메라로 이미지 데이터를 지속적으로 전송합니다. 
온보드 LED 조명은 정전 지역에서 조명과 통신 모두에 사용할 수 있습니다. 
이 논문에서 우리는 또한 VLC 링크 간의 간섭을 피하기위한 드론 포지셔닝 알고리즘을 제시했습니다. 
이는 카메라가 여러 드론으로부터 광학 신호를 수신하기 때문에 드론의 크기와 카메라의 초점 거리에 따라 결정되는 감지 범위 내에서 겹치지 않도록 드론이 이동해야하기 때문입니다. 
제안 된 알고리즘의 성능은 컴퓨터 시뮬레이션을 통해 확인되었습니다. 
또한 LED 패널과 4K 카메라가 장착 된 드론으로 구현 된 PoC를 통해 제안 된 시스템의 타당성을 입증했습니다. 
많은 드론을 활용 한 실험 결과로 제안 된 아이디어의 성능을 평가하는 향후 작업을 구성한다.
